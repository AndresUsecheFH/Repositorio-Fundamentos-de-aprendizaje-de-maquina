{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2SgM2Q0eQY7"
   },
   "source": [
    "Cuaderno con datasets\n",
    "\n",
    "**svm_30k_3_13.csv**\n",
    "\n",
    "**svm_300k_22_16.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNJpL2_4V3Gw",
    "outputId": "701f3a66-bf61-4bcd-ef51-82444a7da1b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/uxlfoundation/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "#Import Library\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.datasets import fetch_covtype\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ektySkqRWUTV"
   },
   "outputs": [],
   "source": [
    "#Se cargan los dataset\n",
    "dfGrande = pd.read_csv(r\"C:\\Users\\wertr\\OneDrive\\Documentos\\Estudios\\TApr\\Taller SVM\\svm_300k_22_16.csv\")\n",
    "dfPequeño = pd.read_csv(r\"C:\\Users\\wertr\\OneDrive\\Documentos\\Estudios\\TApr\\Taller SVM\\svm_30k_3_13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  feature_2  target\n",
      "0   8.323418 -11.438077 -18.234449       4\n",
      "1   3.833288   3.431800 -12.738414       5\n",
      "2 -29.154825 -17.987480  -3.235520       5\n",
      "3  11.297902 -21.558416  -2.026072       4\n",
      "4 -26.499249  -3.102174  11.384092       5\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfPequeño.head())\n",
    "\n",
    "print(dfPequeño.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
      "0  -3.181457  15.916073 -15.736597   1.481453  -0.387107   6.298330   \n",
      "1 -15.618464 -12.483854 -10.082061 -18.571905   5.743069  26.487376   \n",
      "2 -12.395025 -14.189408 -34.003383  12.714051  -5.470940  -0.953249   \n",
      "3  25.880172  13.364500  -1.691390  -3.791963   3.856399 -10.606610   \n",
      "4   4.138190  -7.774099 -13.486021 -22.984050  -2.595998  -1.734654   \n",
      "\n",
      "   feature_6  feature_7  feature_8  feature_9  ...  feature_13  feature_14  \\\n",
      "0 -17.254705   4.212234  11.718630  27.875981  ...  -19.751305   11.536602   \n",
      "1 -13.726256  -5.549255  -9.025683 -10.587104  ...   -3.362816  -25.236207   \n",
      "2  10.271862  18.076215   1.350652 -20.513535  ...   18.824759   -0.110479   \n",
      "3  -3.216215   6.411696  20.052705 -14.311506  ...   18.881624    3.374126   \n",
      "4  15.472967  -2.126888  16.563026  -2.174313  ...    5.422552    9.874498   \n",
      "\n",
      "   feature_15  feature_16  feature_17  feature_18  feature_19  feature_20  \\\n",
      "0   16.540807   -0.827262  -40.056527   -3.378073  -24.613077   15.634938   \n",
      "1  -10.950554    5.424036   16.645737  -14.057690   -5.298769    2.564159   \n",
      "2  -10.122886  -25.760431   22.318763    1.927897  -30.265704    3.681187   \n",
      "3    6.754575  -11.747855   -0.070254   -4.698421   -8.386200   11.532838   \n",
      "4   -0.359733   27.921342  -23.628454  -27.544454   19.827325  -16.540086   \n",
      "\n",
      "   feature_21  target  \n",
      "0   12.249034       3  \n",
      "1    0.063609       5  \n",
      "2  -29.115441       5  \n",
      "3   16.151558       0  \n",
      "4  -15.687348       4  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "Index(['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4',\n",
      "       'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9',\n",
      "       'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14',\n",
      "       'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19',\n",
      "       'feature_20', 'feature_21', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfGrande.head())\n",
    "\n",
    "print(dfGrande.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YP352bOfbcBS"
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1],\n",
    "    'gamma': [ 0.1, 0.01],\n",
    "    'kernel': ['linear',\"rbf\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nModelo: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "nLOBFYuOX96m",
    "outputId": "7d44aa96-2adc-4120-90ba-f3f71ab987b2"
   },
   "outputs": [],
   "source": [
    "#Dataset Pequeño\n",
    "X = dfPequeño.drop('target', axis=1)\n",
    "y = dfPequeño['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, train_size=0.7, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridS = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SVM One-vs-One\n",
      "Accuracy: 0.2788888888888889\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.41      0.35      1125\n",
      "           1       0.24      0.23      0.24      1125\n",
      "           2       0.29      0.35      0.32      1125\n",
      "           3       0.33      0.54      0.41      1125\n",
      "           4       0.30      0.34      0.32      1125\n",
      "           5       0.18      0.07      0.10      1125\n",
      "           6       0.16      0.05      0.08      1125\n",
      "           7       0.24      0.25      0.24      1125\n",
      "\n",
      "    accuracy                           0.28      9000\n",
      "   macro avg       0.26      0.28      0.26      9000\n",
      "weighted avg       0.26      0.28      0.26      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovo = OneVsOneClassifier(GridS)\n",
    "accuracy_ovo = train_and_evaluate(ovo, \"SVM One-vs-One\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SVM One-vs-Rest\n",
      "Accuracy: 0.21633333333333332\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.20      0.23      1125\n",
      "           1       0.19      0.44      0.26      1125\n",
      "           2       0.28      0.22      0.25      1125\n",
      "           3       0.31      0.40      0.35      1125\n",
      "           4       0.24      0.21      0.22      1125\n",
      "           5       0.16      0.09      0.12      1125\n",
      "           6       0.11      0.08      0.09      1125\n",
      "           7       0.15      0.08      0.10      1125\n",
      "\n",
      "    accuracy                           0.22      9000\n",
      "   macro avg       0.21      0.22      0.20      9000\n",
      "weighted avg       0.21      0.22      0.20      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(GridS)\n",
    "accuracy_ovr = train_and_evaluate(ovr, \"SVM One-vs-Rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Grande\n",
    "X = dfGrande.drop('target', axis=1)\n",
    "y = dfGrande['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, train_size=0.7, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridS = GridSearchCV(svc, param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SVM One-vs-One\n",
      "Accuracy: 0.6007111111111111\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58     11250\n",
      "           1       0.64      0.67      0.65     11250\n",
      "           2       0.56      0.54      0.55     11250\n",
      "           3       0.65      0.68      0.67     11250\n",
      "           4       0.62      0.62      0.62     11250\n",
      "           5       0.61      0.62      0.62     11250\n",
      "           6       0.60      0.60      0.60     11250\n",
      "           7       0.53      0.50      0.51     11250\n",
      "\n",
      "    accuracy                           0.60     90000\n",
      "   macro avg       0.60      0.60      0.60     90000\n",
      "weighted avg       0.60      0.60      0.60     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovo = OneVsOneClassifier(GridS)\n",
    "accuracy_ovo = train_and_evaluate(ovo, \"SVM One-vs-One\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,10],\n",
    "    'gamma': [ 0.1, 0.01,0.001],\n",
    "    'kernel': ['linear',\"rbf\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmuestra = dfGrande.sample(frac=0.1, random_state=42)\n",
    "X = dfmuestra.drop('target', axis=1)\n",
    "y = dfmuestra['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, train_size=0.7, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SVM One-vs-Rest\n",
      "Accuracy: 0.5951111111111111\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.55      0.57      1138\n",
      "           1       0.65      0.67      0.66      1127\n",
      "           2       0.51      0.56      0.53      1105\n",
      "           3       0.66      0.68      0.67      1135\n",
      "           4       0.63      0.60      0.61      1102\n",
      "           5       0.62      0.60      0.61      1123\n",
      "           6       0.61      0.60      0.60      1126\n",
      "           7       0.50      0.51      0.50      1144\n",
      "\n",
      "    accuracy                           0.60      9000\n",
      "   macro avg       0.60      0.60      0.60      9000\n",
      "weighted avg       0.60      0.60      0.60      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(GridS)\n",
    "accuracy_ovr = train_and_evaluate(ovr, \"SVM One-vs-Rest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores hiperparámetros encontrados para la clase 3:\n",
      "Best score (cross-val): 0.9176\n",
      "Best params: {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = None\n",
    "best_class = None\n",
    "\n",
    "for i, estimator in enumerate(ovr.estimators_):\n",
    "    if estimator.best_score_ > best_score:\n",
    "        best_score = estimator.best_score_\n",
    "        best_params = estimator.best_params_\n",
    "        best_class = i\n",
    "\n",
    "print(f\"\\nMejores hiperparámetros encontrados para la clase {best_class}:\")\n",
    "print(f\"Best score (cross-val): {best_score:.4f}\")\n",
    "print(f\"Best params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se utilizan los datos completos\n",
    "X = dfGrande.drop('target', axis=1)\n",
    "y = dfGrande['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y, train_size=0.7, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SVM One-vs-Rest\n",
      "Accuracy: 0.5988333333333333\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.59      0.58     11250\n",
      "           1       0.62      0.68      0.65     11250\n",
      "           2       0.57      0.52      0.55     11250\n",
      "           3       0.63      0.69      0.66     11250\n",
      "           4       0.60      0.63      0.62     11250\n",
      "           5       0.60      0.63      0.61     11250\n",
      "           6       0.60      0.61      0.60     11250\n",
      "           7       0.57      0.43      0.49     11250\n",
      "\n",
      "    accuracy                           0.60     90000\n",
      "   macro avg       0.60      0.60      0.60     90000\n",
      "weighted avg       0.60      0.60      0.60     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Modelo con los mejores parametros para el entrenamiento segun la prueba\n",
    "best_svc = SVC(C=1, gamma=0.01, kernel='rbf', probability=False)\n",
    "final_model = OneVsRestClassifier(best_svc)\n",
    "\n",
    "# Entrenar el modelo con los datos completos de entrenamiento\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"\\nModelo: SVM One-vs-Rest\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
